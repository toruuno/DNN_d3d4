{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "4_3_keras_codes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toruuno/DNN_d3d4/blob/master/4_3_keras_codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cNl2QA_Rnv5"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkwjN1jNVAYy"
      },
      "source": [
        "## Googleドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvFXpiH3EVC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3fffb6-7638-4730-ac59-f92aa135c82f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ub7RYdeY6pK"
      },
      "source": [
        "## sys.pathの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oql7L19rEsWi"
      },
      "source": [
        "以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ic2JzkvFX59"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/DNN_code_colab_lesson_3_4')\n",
        "sys.path.append('/content/drive/My Drive/DNN_code_colab_lesson_3_4/common')\n",
        "sys.path.append('/content/drive/My Drive/DNN_code_colab_lesson_3_4/lesson4')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9Mnk83cNxze",
        "outputId": "30af4d10-d617-407b-e804-b01656d85f5d"
      },
      "source": [
        "#!pip install tensorflow==2.6.0\n",
        "#!pip install tensorflow==1.9.0\n",
        "#!pip install tensorflow==1.15.5\n",
        "\n",
        "#おまじない(このコードはtf1.9.0っぽいけどつじつま合わせる為には以下を打てばよいらしい)\n",
        "#ただし1.15.2までしか戻れない様で・・・残念ながら一部コードのErrorが解決せず\n",
        "#とりあえず諦めて実行可能なコードだけ実行させる(解決方法がわかれば適宜解決している)\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ulevs1XUUsj",
        "outputId": "8ccb27d7-7957-473b-cc7f-704f621f02eb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLlq0vfB2xeJ"
      },
      "source": [
        "# keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQNC_-NI2xeL"
      },
      "source": [
        "## 線形回帰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdix662X2xeM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89059eff-c068-42b3-8a5e-6ff70e25ad1b"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iters_num = 1000\n",
        "plot_interval = 10\n",
        "\n",
        "x = np.linspace(-1, 1, 200)\n",
        "np.random.shuffle(x)\n",
        "d = 0.5 * x + 2 + np.random.normal(0, 0.05, (200,))\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# モデルを作成\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=1, units=1))\n",
        "# model.add(Dense(input_dim=1, output_dim=1))\n",
        "\n",
        "# モデルを表示\n",
        "model.summary()\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(loss='mse', optimizer='sgd')\n",
        "\n",
        "# train\n",
        "for i in range(iters_num):\n",
        "    loss = model.train_on_batch(x, d)\n",
        "    if (i+1) % plot_interval == 0:\n",
        "        print('Generation: ' + str(i+1) + '. 誤差 = ' + str(loss))\n",
        "\n",
        "W, b = model.layers[0].get_weights()\n",
        "print('W:', W)\n",
        "print('b:', b)\n",
        "\n",
        "y = model.predict(x)\n",
        "plt.scatter(x, d)\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation: 10. 誤差 = 2.999926\n",
            "Generation: 20. 誤差 = 2.0469923\n",
            "Generation: 30. 誤差 = 1.4053259\n",
            "Generation: 40. 誤差 = 0.9721565\n",
            "Generation: 50. 誤差 = 0.67878675\n",
            "Generation: 60. 誤差 = 0.47927722\n",
            "Generation: 70. 誤差 = 0.34289104\n",
            "Generation: 80. 誤差 = 0.24904996\n",
            "Generation: 90. 誤差 = 0.18396498\n",
            "Generation: 100. 誤差 = 0.13838562\n",
            "Generation: 110. 誤差 = 0.1060974\n",
            "Generation: 120. 誤差 = 0.082917444\n",
            "Generation: 130. 誤差 = 0.06602337\n",
            "Generation: 140. 誤差 = 0.053505305\n",
            "Generation: 150. 誤差 = 0.044065267\n",
            "Generation: 160. 誤差 = 0.03681705\n",
            "Generation: 170. 誤差 = 0.031151647\n",
            "Generation: 180. 誤差 = 0.026647434\n",
            "Generation: 190. 誤差 = 0.02300968\n",
            "Generation: 200. 誤差 = 0.020030092\n",
            "Generation: 210. 誤差 = 0.017559566\n",
            "Generation: 220. 誤差 = 0.015489722\n",
            "Generation: 230. 誤差 = 0.013740537\n",
            "Generation: 240. 誤差 = 0.01225184\n",
            "Generation: 250. 誤差 = 0.010977622\n",
            "Generation: 260. 誤差 = 0.009882014\n",
            "Generation: 270. 誤差 = 0.008936621\n",
            "Generation: 280. 誤差 = 0.008118552\n",
            "Generation: 290. 誤差 = 0.007409108\n",
            "Generation: 300. 誤差 = 0.006792827\n",
            "Generation: 310. 誤差 = 0.0062567703\n",
            "Generation: 320. 誤差 = 0.005790023\n",
            "Generation: 330. 誤差 = 0.005383311\n",
            "Generation: 340. 誤差 = 0.005028699\n",
            "Generation: 350. 誤差 = 0.0047193686\n",
            "Generation: 360. 誤差 = 0.004449446\n",
            "Generation: 370. 誤差 = 0.00421385\n",
            "Generation: 380. 誤差 = 0.004008169\n",
            "Generation: 390. 誤差 = 0.0038285744\n",
            "Generation: 400. 誤差 = 0.0036717462\n",
            "Generation: 410. 誤差 = 0.0035347769\n",
            "Generation: 420. 誤差 = 0.0034151503\n",
            "Generation: 430. 誤差 = 0.0033106622\n",
            "Generation: 440. 誤差 = 0.0032193915\n",
            "Generation: 450. 誤差 = 0.003139666\n",
            "Generation: 460. 誤差 = 0.0030700227\n",
            "Generation: 470. 誤差 = 0.003009186\n",
            "Generation: 480. 誤差 = 0.0029560404\n",
            "Generation: 490. 誤差 = 0.0029096154\n",
            "Generation: 500. 誤差 = 0.0028690582\n",
            "Generation: 510. 誤差 = 0.0028336283\n",
            "Generation: 520. 誤差 = 0.0028026777\n",
            "Generation: 530. 誤差 = 0.0027756386\n",
            "Generation: 540. 誤差 = 0.0027520177\n",
            "Generation: 550. 誤差 = 0.0027313826\n",
            "Generation: 560. 誤差 = 0.0027133557\n",
            "Generation: 570. 誤差 = 0.0026976073\n",
            "Generation: 580. 誤差 = 0.0026838502\n",
            "Generation: 590. 誤差 = 0.0026718306\n",
            "Generation: 600. 誤差 = 0.0026613318\n",
            "Generation: 610. 誤差 = 0.00265216\n",
            "Generation: 620. 誤差 = 0.0026441459\n",
            "Generation: 630. 誤差 = 0.0026371449\n",
            "Generation: 640. 誤差 = 0.002631031\n",
            "Generation: 650. 誤差 = 0.0026256875\n",
            "Generation: 660. 誤差 = 0.0026210207\n",
            "Generation: 670. 誤差 = 0.0026169438\n",
            "Generation: 680. 誤差 = 0.0026133817\n",
            "Generation: 690. 誤差 = 0.0026102702\n",
            "Generation: 700. 誤差 = 0.0026075512\n",
            "Generation: 710. 誤差 = 0.0026051775\n",
            "Generation: 720. 誤差 = 0.002603102\n",
            "Generation: 730. 誤差 = 0.0026012894\n",
            "Generation: 740. 誤差 = 0.0025997076\n",
            "Generation: 750. 誤差 = 0.0025983236\n",
            "Generation: 760. 誤差 = 0.002597115\n",
            "Generation: 770. 誤差 = 0.0025960593\n",
            "Generation: 780. 誤差 = 0.0025951373\n",
            "Generation: 790. 誤差 = 0.0025943317\n",
            "Generation: 800. 誤差 = 0.0025936281\n",
            "Generation: 810. 誤差 = 0.002593012\n",
            "Generation: 820. 誤差 = 0.002592476\n",
            "Generation: 830. 誤差 = 0.0025920067\n",
            "Generation: 840. 誤差 = 0.0025915965\n",
            "Generation: 850. 誤差 = 0.0025912384\n",
            "Generation: 860. 誤差 = 0.0025909257\n",
            "Generation: 870. 誤差 = 0.0025906533\n",
            "Generation: 880. 誤差 = 0.002590414\n",
            "Generation: 890. 誤差 = 0.0025902058\n",
            "Generation: 900. 誤差 = 0.0025900232\n",
            "Generation: 910. 誤差 = 0.0025898644\n",
            "Generation: 920. 誤差 = 0.002589725\n",
            "Generation: 930. 誤差 = 0.0025896034\n",
            "Generation: 940. 誤差 = 0.0025894972\n",
            "Generation: 950. 誤差 = 0.0025894037\n",
            "Generation: 960. 誤差 = 0.0025893233\n",
            "Generation: 970. 誤差 = 0.0025892525\n",
            "Generation: 980. 誤差 = 0.0025891915\n",
            "Generation: 990. 誤差 = 0.0025891364\n",
            "Generation: 1000. 誤差 = 0.0025890903\n",
            "W: [[0.4976611]]\n",
            "b: [2.002266]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTd6I_kw2xeP"
      },
      "source": [
        "## 単純パーセプトロン \n",
        "OR回路\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "### [try]\n",
        "-  np.random.seed(0)をnp.random.seed(1)に変更\n",
        "-  エポック数を100に変更\n",
        "-  AND回路, XOR回路に変更\n",
        "-  OR回路にしてバッチサイズを10に変更\n",
        "-  エポック数を300に変更しよう\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1L1WE642xeP"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def try_0(seed=0,epochs=30,logicMode=0,batch_size=1):\n",
        "    # logging levelを変更\n",
        "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "    # モジュール読み込み\n",
        "    import numpy as np\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation\n",
        "    from keras.optimizers import SGD\n",
        "    \n",
        "    # 乱数を固定値で初期化\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # シグモイドの単純パーセプトロン作成\n",
        "    model = Sequential()\n",
        "    model.add(Dense(input_dim=2, units=1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))\n",
        "    \n",
        "    # トレーニング用入力 X と正解データ T\n",
        "    X = np.array( [[0,0], [0,1], [1,0], [1,1]] )\n",
        "    #T = np.array( [[0], [1], [1], [1]] )\n",
        "    T = None\n",
        "    if logicMode==1:\n",
        "        print(\"AND\")\n",
        "        T=np.array([[0], [0], [0], [1]])\n",
        "    elif logicMode==2:\n",
        "        print(\"XOR\")\n",
        "        T=np.array([[0], [1], [1], [0]])\n",
        "    else:\n",
        "        print(\"OR\")\n",
        "        T=np.array( [[0], [1], [1], [1]] )\n",
        "\n",
        "    # トレーニング\n",
        "    model.fit(X, T, epochs=epochs, batch_size=batch_size)\n",
        "    \n",
        "    # トレーニングの入力を流用して実際に分類\n",
        "    Y = model.predict_classes(X, batch_size=batch_size)\n",
        "\n",
        "    print(\"TEST\")\n",
        "    print(Y == T)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLLBv2ggdm3P",
        "outputId": "0f670b08-c208-4ff8-857d-573c7cd5f7cd"
      },
      "source": [
        "#デフォルト状態を出しておく\n",
        "try_0()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "OR\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4352\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4204\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4079\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3971\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3876\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3790\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3717\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3650\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3586\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3528\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3476\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3425\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3378\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3333\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3291\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3250\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3210\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3172\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3136\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3100\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3067\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3032\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3000\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2968\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2938\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2908\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2878\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2850\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2821\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2794\n",
            "TEST\n",
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8UUTCyYe8Yy",
        "outputId": "ae7f0f13-d6d7-46c1-9302-3e98bff0f6c7"
      },
      "source": [
        "#seedの変更\n",
        "#失敗する\n",
        "try_0(seed=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "OR\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4976\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4734\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4528\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4364\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4231\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4115\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4016\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3928\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3852\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3781\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3719\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3661\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3605\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3555\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3506\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3460\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3417\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3375\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3334\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3294\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3257\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3220\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3186\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3151\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3117\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3085\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3053\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3022\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2991\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2961\n",
            "TEST\n",
            "[[False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKpWAS42fGLC",
        "outputId": "38959467-2aa2-4368-a073-e73c9db989d3"
      },
      "source": [
        "#epoch数を100に(相違を見るのでseedも1に)\n",
        "#ちゃんと収束できている\n",
        "try_0(seed=1,epochs=100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "OR\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.4976\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4734\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4528\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4364\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4231\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4115\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4016\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3928\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3852\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3781\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3719\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3661\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3605\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3555\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3506\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3460\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3417\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3375\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3334\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3294\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3257\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3220\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3186\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3151\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3117\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3085\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3053\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3022\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2991\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2961\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2931\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2903\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2875\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2847\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2820\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2794\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2767\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2741\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2716\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2691\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2667\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2643\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2619\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2596\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2573\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2551\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2528\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2507\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2485\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2464\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2443\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2423\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2403\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2383\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2363\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2344\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2325\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2307\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2288\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2270\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2252\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2235\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2217\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2200\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2183\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2167\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2151\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2134\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2118\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2103\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2087\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2072\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2057\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2042\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2027\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2013\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1998\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1984\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1970\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1957\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1943\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1930\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1917\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1904\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1891\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1878\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1865\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1853\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1841\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1829\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1817\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1805\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1793\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1782\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1770\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1759\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1748\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1737\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1726\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1715\n",
            "TEST\n",
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ2jw0EWfd_v",
        "outputId": "c1e9eac8-b2f7-41f0-aab4-5390cde040ca"
      },
      "source": [
        "#AND回路に変更\n",
        "#無理がないのでまぁ収束はする\n",
        "try_0(logicMode=1)\n",
        "\n",
        "#XOR回路に変更\n",
        "#弱そう\n",
        "try_0(logicMode=2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "AND\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.8084\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7406\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6849\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6409\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6056\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5781\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5573\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5409\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5270\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5151\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5051\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4965\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4889\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4818\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4751\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4682\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4623\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4565\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4512\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4459\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4403\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4354\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4309\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4264\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4219\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4176\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4132\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4090\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4046\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4011\n",
            "TEST\n",
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "XOR\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.8427\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8205\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8049\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7924\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7822\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7754\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7688\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7622\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7578\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7555\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7520\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7497\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7468\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7454\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7439\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7425\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7422\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7404\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7394\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7393\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7380\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7368\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7371\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7363\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7356\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7348\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7344\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7338\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7328\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7326\n",
            "TEST\n",
            "[[ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3snx_FGvf431",
        "outputId": "3b17bd4c-af48-4bd8-a63a-a52fe200086d"
      },
      "source": [
        "#epochsを10に変更(OR回路)\n",
        "#収束するのにエポック数10は足りないという事になる\n",
        "try_0(epochs=10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "OR\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.4352\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4204\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4079\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3971\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3876\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3790\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3717\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3650\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3586\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3528\n",
            "TEST\n",
            "[[False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIzAMvk2gA4K",
        "outputId": "930daf30-5bc6-4702-e560-559cf3808d76"
      },
      "source": [
        "#epochsを300と1000に変更(XOR回路)\n",
        "#排他論理和に対してとにかく弱いモデルとわかった\n",
        "#重みを消すわけにいかない(意味があるので)\n",
        "#2bitのパーセプトロンの和だけだと確かに難しそう\n",
        "#1bitだけ立った状態は1にしないといけないけど2bit立ったら0にというのが矛盾\n",
        "#出力も2bitにして下位桁の状態を出力する様なモデルだと可能かな？\n",
        "try_0(epochs=300, logicMode=2)\n",
        "try_0(epochs=1000, logicMode=2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_19 (Dense)             (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "XOR\n",
            "Epoch 1/300\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.8427\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8205\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8049\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7924\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7822\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7754\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7688\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7622\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7578\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7555\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7520\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7497\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7468\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7454\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7439\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7425\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7422\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7404\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7394\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7393\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7380\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7368\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7371\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7363\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7356\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7348\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7344\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7338\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7328\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7326\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7319\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7317\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7304\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7306\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7304\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7293\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7295\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7281\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7280\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7282\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7276\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7277\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7274\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7270\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7267\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7262\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7251\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7249\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7247\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7244\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7246\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7250\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7246\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7242\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7241\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7242\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7233\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7237\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7235\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7228\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7232\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7231\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7229\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7224\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7225\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7215\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7224\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7219\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7218\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7221\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7220\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7219\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7211\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7210\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7213\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7216\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7205\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7213\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7214\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7213\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7205\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7204\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7210\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7206\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7209\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7208\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7206\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7207\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7196\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7206\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7198\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7202\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7203\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7197\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7200\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7196\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7200\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7203\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7203\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7195\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7201\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7194\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7200\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7199\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7193\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7199\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7192\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7197\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7194\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7198\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7196\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7197\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7196\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7194\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7196\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7192\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7194\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7195\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7195\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7193\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7185\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7192\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7193\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7187\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7193\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7194\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7194\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7187\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7191\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7193\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7183\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7191\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7186\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7193\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7186\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7193\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7193\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7189\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7191\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7185\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7192\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7191\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7193\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7191\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7189\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7192\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7185\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7182\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7192\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7192\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7188\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7185\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7192\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7191\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7181\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7191\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7192\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7181\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7192\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7185\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7186\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7191\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7192\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7189\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7189\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7184\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7191\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7189\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7189\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7189\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7187\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7181\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7181\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7192\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7189\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7189\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7183\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7187\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "TEST\n",
            "[[False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]]\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "XOR\n",
            "Epoch 1/1000\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.8427\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8205\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8049\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7924\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7822\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7754\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7688\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7622\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7578\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7555\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7520\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7497\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7468\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7454\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7439\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7425\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7422\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7404\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7394\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7393\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7380\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7368\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7371\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7363\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7356\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7348\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7344\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7338\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7328\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7326\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7319\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7317\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7304\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7306\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7304\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7293\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7295\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7281\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7280\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7282\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7276\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7277\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7274\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7270\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7267\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7262\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7251\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7249\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7247\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7244\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7246\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7250\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7246\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7242\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7241\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7242\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7233\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7237\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7235\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7228\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7232\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7231\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7229\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7224\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7225\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7215\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7224\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7219\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7218\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7221\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7220\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7219\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7211\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7210\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7213\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7216\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7205\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7213\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7214\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7213\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7205\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7204\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7210\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7206\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7209\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7208\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7206\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7207\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7196\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7206\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7198\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7202\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7203\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7197\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7200\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7196\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7200\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7203\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7203\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7195\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7201\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7194\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7200\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7199\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7193\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7199\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7192\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7197\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7194\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7198\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7196\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7197\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7196\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7194\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7196\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7192\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7194\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7195\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7195\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7193\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7192\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7193\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7193\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7194\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7194\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7191\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7193\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7186\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7193\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7193\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7193\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7185\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7192\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7191\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7193\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7189\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7192\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7185\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7185\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7182\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7192\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7192\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7185\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7188\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7188\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7185\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7185\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7192\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7181\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7191\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7192\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7181\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7192\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7185\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7185\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7186\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7192\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7189\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7191\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7189\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7184\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7184\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7189\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7184\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7189\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7190\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7187\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7181\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7181\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7192\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7180\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7189\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7184\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7184\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7187\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7187\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7187\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7180\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7184\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7190\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7188\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7191\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7189\n",
            "Epoch 329/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 330/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 331/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 332/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 333/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 334/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 335/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 336/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 337/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 338/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 339/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 340/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 341/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 342/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 343/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 344/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 345/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 346/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 347/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 348/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 349/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 350/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 351/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 352/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 353/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 354/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 355/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 356/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 357/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 358/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 359/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 360/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 361/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7181\n",
            "Epoch 362/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7185\n",
            "Epoch 363/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7189\n",
            "Epoch 364/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7186\n",
            "Epoch 365/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7185\n",
            "Epoch 366/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 367/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7181\n",
            "Epoch 368/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7189\n",
            "Epoch 369/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 370/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7181\n",
            "Epoch 371/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 372/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 373/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 374/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 375/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 376/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 377/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 378/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 379/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 380/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7183\n",
            "Epoch 381/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 382/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 383/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 384/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 385/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 386/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7190\n",
            "Epoch 387/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 388/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 389/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7180\n",
            "Epoch 390/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7181\n",
            "Epoch 391/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 392/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7189\n",
            "Epoch 393/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 394/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7184\n",
            "Epoch 395/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 396/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 397/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 398/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7188\n",
            "Epoch 399/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 400/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 401/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 402/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7188\n",
            "Epoch 403/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 404/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 405/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 406/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 407/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 408/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 409/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 410/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 411/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 412/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 413/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 414/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7180\n",
            "Epoch 415/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 416/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 417/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 418/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 419/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 420/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 421/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 422/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 423/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 424/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 425/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 426/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7186\n",
            "Epoch 427/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 428/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 429/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 430/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 431/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 432/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 433/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 434/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 435/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7188\n",
            "Epoch 436/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 437/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 438/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7183\n",
            "Epoch 439/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 440/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 441/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 442/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 443/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 444/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 445/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 446/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 447/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7183\n",
            "Epoch 448/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 449/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 450/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 451/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 452/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 453/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7186\n",
            "Epoch 454/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 455/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 456/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 457/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 458/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7183\n",
            "Epoch 459/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 460/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 461/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 462/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 463/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7186\n",
            "Epoch 464/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7190\n",
            "Epoch 465/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 466/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 467/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 468/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 469/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 470/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 471/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 472/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 473/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 474/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 475/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 476/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 477/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 478/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 479/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7188\n",
            "Epoch 480/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 481/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 482/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 483/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7180\n",
            "Epoch 484/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7181\n",
            "Epoch 485/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 486/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7185\n",
            "Epoch 487/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7192\n",
            "Epoch 488/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7189\n",
            "Epoch 489/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7192\n",
            "Epoch 490/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7182\n",
            "Epoch 491/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7192\n",
            "Epoch 492/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7182\n",
            "Epoch 493/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 494/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7193\n",
            "Epoch 495/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 496/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7189\n",
            "Epoch 497/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 498/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 499/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 500/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7183\n",
            "Epoch 501/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 502/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 503/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 504/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 505/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 506/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7184\n",
            "Epoch 507/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 508/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7190\n",
            "Epoch 509/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 510/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 511/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 512/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 513/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 514/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 515/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 516/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7180\n",
            "Epoch 517/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 518/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 519/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 520/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7187\n",
            "Epoch 521/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 522/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 523/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7187\n",
            "Epoch 524/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7187\n",
            "Epoch 525/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 526/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7184\n",
            "Epoch 527/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7189\n",
            "Epoch 528/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 529/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 530/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7189\n",
            "Epoch 531/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 532/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 533/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7187\n",
            "Epoch 534/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7187\n",
            "Epoch 535/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 536/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 537/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 538/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 539/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 540/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 541/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 542/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 543/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 544/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 545/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 546/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 547/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 548/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 549/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 550/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7186\n",
            "Epoch 551/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7190\n",
            "Epoch 552/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 553/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 554/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7186\n",
            "Epoch 555/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 556/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7190\n",
            "Epoch 557/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 558/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 559/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 560/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 561/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 562/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 563/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 564/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 565/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 566/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 567/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 568/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7184\n",
            "Epoch 569/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7191\n",
            "Epoch 570/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 571/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 572/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7180\n",
            "Epoch 573/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 574/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 575/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 576/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 577/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 578/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7188\n",
            "Epoch 579/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7186\n",
            "Epoch 580/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 581/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 582/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7190\n",
            "Epoch 583/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 584/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 585/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7189\n",
            "Epoch 586/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7180\n",
            "Epoch 587/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 588/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 589/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 590/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7190\n",
            "Epoch 591/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 592/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 593/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 594/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 595/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 596/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 597/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 598/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 599/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 600/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 601/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 602/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 603/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 604/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 605/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7190\n",
            "Epoch 606/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 607/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 608/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 609/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 610/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 611/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 612/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7180\n",
            "Epoch 613/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7179\n",
            "Epoch 614/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 615/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 616/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 617/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 618/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 619/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 620/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 621/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 622/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7179\n",
            "Epoch 623/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 624/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 625/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 626/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 627/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 628/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7187\n",
            "Epoch 629/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 630/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 631/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 632/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7183\n",
            "Epoch 633/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7188\n",
            "Epoch 634/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 635/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 636/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 637/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 638/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 639/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 640/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 641/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 642/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 643/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 644/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 645/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 646/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 647/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7188\n",
            "Epoch 648/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 649/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 650/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 651/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 652/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 653/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 654/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 655/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7183\n",
            "Epoch 656/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 657/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 658/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 659/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 660/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 661/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 662/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 663/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 664/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 665/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7184\n",
            "Epoch 666/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 667/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 668/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 669/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7186\n",
            "Epoch 670/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7186\n",
            "Epoch 671/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 672/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 673/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 674/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7188\n",
            "Epoch 675/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7180\n",
            "Epoch 676/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 677/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 678/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 679/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 680/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 681/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 682/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 683/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 684/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 685/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 686/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 687/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 688/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 689/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 690/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7179\n",
            "Epoch 691/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 692/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 693/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 694/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 695/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 696/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 697/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 698/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 699/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 700/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 701/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 702/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7185\n",
            "Epoch 703/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7182\n",
            "Epoch 704/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7192\n",
            "Epoch 705/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 706/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 707/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 708/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 709/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 710/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 711/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7190\n",
            "Epoch 712/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 713/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 714/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 715/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7179\n",
            "Epoch 716/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 717/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 718/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7184\n",
            "Epoch 719/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 720/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7180\n",
            "Epoch 721/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7187\n",
            "Epoch 722/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 723/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7189\n",
            "Epoch 724/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7184\n",
            "Epoch 725/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 726/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7185\n",
            "Epoch 727/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7184\n",
            "Epoch 728/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 729/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 730/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 731/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 732/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 733/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 734/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7184\n",
            "Epoch 735/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7189\n",
            "Epoch 736/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 737/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7187\n",
            "Epoch 738/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 739/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 740/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 741/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 742/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7187\n",
            "Epoch 743/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 744/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 745/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 746/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7190\n",
            "Epoch 747/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 748/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7186\n",
            "Epoch 749/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 750/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 751/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 752/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 753/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 754/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 755/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 756/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 757/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7187\n",
            "Epoch 758/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 759/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 760/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7181\n",
            "Epoch 761/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7184\n",
            "Epoch 762/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7180\n",
            "Epoch 763/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7191\n",
            "Epoch 764/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 765/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 766/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7181\n",
            "Epoch 767/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 768/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 769/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 770/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 771/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 772/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 773/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 774/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 775/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 776/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 777/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 778/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 779/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 780/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 781/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 782/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 783/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 784/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 785/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 786/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 787/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 788/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 789/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 790/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7190\n",
            "Epoch 791/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 792/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 793/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 794/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 795/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 796/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7191\n",
            "Epoch 797/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7184\n",
            "Epoch 798/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 799/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 800/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 801/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 802/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 803/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 804/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 805/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 806/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 807/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 808/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 809/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 810/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 811/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 812/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 813/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 814/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 815/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 816/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7186\n",
            "Epoch 817/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 818/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 819/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 820/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 821/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 822/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7181\n",
            "Epoch 823/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7182\n",
            "Epoch 824/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 825/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7193\n",
            "Epoch 826/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7192\n",
            "Epoch 827/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 828/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 829/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 830/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 831/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 832/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7184\n",
            "Epoch 833/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 834/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 835/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 836/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 837/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7181\n",
            "Epoch 838/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7191\n",
            "Epoch 839/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 840/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 841/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 842/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 843/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 844/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 845/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 846/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 847/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 848/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 849/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 850/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7190\n",
            "Epoch 851/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 852/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 853/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 854/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 855/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7190\n",
            "Epoch 856/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7186\n",
            "Epoch 857/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 858/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 859/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 860/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 861/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 862/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 863/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 864/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 865/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 866/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 867/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 868/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 869/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 870/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 871/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 872/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 873/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 874/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7188\n",
            "Epoch 875/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 876/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 877/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 878/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 879/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 880/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 881/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 882/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 883/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7190\n",
            "Epoch 884/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 885/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 886/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 887/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 888/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 889/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 890/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7188\n",
            "Epoch 891/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 892/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7183\n",
            "Epoch 893/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 894/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 895/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 896/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 897/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 898/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7181\n",
            "Epoch 899/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 900/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7191\n",
            "Epoch 901/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 902/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7185\n",
            "Epoch 903/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7182\n",
            "Epoch 904/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7192\n",
            "Epoch 905/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 906/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 907/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7181\n",
            "Epoch 908/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 909/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 910/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 911/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 912/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7191\n",
            "Epoch 913/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 914/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7188\n",
            "Epoch 915/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7186\n",
            "Epoch 916/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7188\n",
            "Epoch 917/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 918/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 919/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 920/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 921/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 922/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 923/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 924/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 925/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 926/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7189\n",
            "Epoch 927/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 928/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 929/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 930/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 931/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 932/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 933/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 934/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 935/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 936/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 937/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 938/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 939/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 940/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 941/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 942/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 943/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7186\n",
            "Epoch 944/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7187\n",
            "Epoch 945/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 946/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 947/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 948/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 949/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 950/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 951/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7187\n",
            "Epoch 952/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 953/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 954/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 955/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 956/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 957/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 958/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7184\n",
            "Epoch 959/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7180\n",
            "Epoch 960/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7188\n",
            "Epoch 961/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 962/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 963/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 964/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7186\n",
            "Epoch 965/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 966/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7180\n",
            "Epoch 967/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7180\n",
            "Epoch 968/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 969/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7183\n",
            "Epoch 970/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 971/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 972/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 973/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 974/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 975/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 976/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 977/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7180\n",
            "Epoch 978/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7183\n",
            "Epoch 979/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7186\n",
            "Epoch 980/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 981/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7186\n",
            "Epoch 982/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7190\n",
            "Epoch 983/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7190\n",
            "Epoch 984/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7183\n",
            "Epoch 985/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7183\n",
            "Epoch 986/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7191\n",
            "Epoch 987/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7180\n",
            "Epoch 988/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7183\n",
            "Epoch 989/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7190\n",
            "Epoch 990/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7190\n",
            "Epoch 991/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 992/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7183\n",
            "Epoch 993/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 994/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7180\n",
            "Epoch 995/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7191\n",
            "Epoch 996/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7187\n",
            "Epoch 997/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7188\n",
            "Epoch 998/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7188\n",
            "Epoch 999/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7185\n",
            "Epoch 1000/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7192\n",
            "TEST\n",
            "[[False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bT4_iOk2xeS"
      },
      "source": [
        "## 分類 (iris)\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "### [try]\n",
        "-  中間層の活性関数をsigmoidに変更しよう\n",
        "-  SGDをimportしoptimizerをSGD(lr=0.1)に変更しよう\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ6_puLL2xeS"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def try_1(act=0,opt=0,learning_rate=0.1):\n",
        "    # logging levelを変更\n",
        "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn import datasets\n",
        "    iris = datasets.load_iris()\n",
        "    x = iris.data\n",
        "    d = iris.target\n",
        "\n",
        "    # from sklearn.cross_validation import train_test_split\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    x_train, x_test, d_train, d_test = train_test_split(x, d, test_size=0.2)\n",
        "\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Activation\n",
        "    from keras.optimizers import SGD\n",
        "\n",
        "    #モデルの設定\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=4))\n",
        "    if act==0:\n",
        "        print(\"ReLU\")\n",
        "        model.add(Activation('relu'))\n",
        "    else:\n",
        "        print(\"sigmoid\")\n",
        "        model.add(Activation('sigmoid'))\n",
        "    model.add(Dense(3, input_dim=12))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    if opt == 0:\n",
        "        print(\"sgd\")\n",
        "        model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    else:\n",
        "        print(\"keras.SGD\")\n",
        "        model.compile(optimizer=SGD(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(x_train, d_train, batch_size=5, epochs=20, verbose=1, validation_data=(x_test, d_test))\n",
        "    loss = model.evaluate(x_test, d_test, verbose=0)\n",
        "\n",
        "    #Accuracy\n",
        "\n",
        "    #なんかkeyエラーだってよ\n",
        "    #plt.plot(history.history['acc']) \n",
        "    #plt.plot(history.history['val_acc'])\n",
        "    print(history.history.keys())\n",
        "    plt.plot(history.history['accuracy']) #一応候補からそれらしいのを選択しなおす\n",
        "    plt.plot(history.history['val_accuracy']) #一応候補からそれらしいのを選択しなおす\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.show()\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Uo8Tl1AJmgSZ",
        "outputId": "df9b89ff-d5e0-446e-e261-140d422a83c4"
      },
      "source": [
        "#デフォルト\n",
        "try_1()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReLU\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 12)                60        \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 3)                 39        \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 99\n",
            "Trainable params: 99\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "sgd\n",
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/20\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 1.1840 - accuracy: 0.0500 - val_loss: 1.0050 - val_accuracy: 0.3667\n",
            "Epoch 2/20\n",
            "120/120 [==============================] - 0s 636us/step - loss: 0.9239 - accuracy: 0.6667 - val_loss: 0.8782 - val_accuracy: 0.8667\n",
            "Epoch 3/20\n",
            "120/120 [==============================] - 0s 686us/step - loss: 0.7943 - accuracy: 0.8500 - val_loss: 0.7880 - val_accuracy: 0.6667\n",
            "Epoch 4/20\n",
            "120/120 [==============================] - 0s 654us/step - loss: 0.6951 - accuracy: 0.8417 - val_loss: 0.6920 - val_accuracy: 0.8333\n",
            "Epoch 5/20\n",
            "120/120 [==============================] - 0s 669us/step - loss: 0.6136 - accuracy: 0.9083 - val_loss: 0.6301 - val_accuracy: 0.8667\n",
            "Epoch 6/20\n",
            "120/120 [==============================] - 0s 674us/step - loss: 0.5465 - accuracy: 0.8917 - val_loss: 0.5927 - val_accuracy: 0.8000\n",
            "Epoch 7/20\n",
            "120/120 [==============================] - 0s 789us/step - loss: 0.4962 - accuracy: 0.9000 - val_loss: 0.5407 - val_accuracy: 0.9333\n",
            "Epoch 8/20\n",
            "120/120 [==============================] - 0s 646us/step - loss: 0.4742 - accuracy: 0.9250 - val_loss: 0.5196 - val_accuracy: 0.8000\n",
            "Epoch 9/20\n",
            "120/120 [==============================] - 0s 645us/step - loss: 0.4296 - accuracy: 0.9000 - val_loss: 0.5079 - val_accuracy: 0.8000\n",
            "Epoch 10/20\n",
            "120/120 [==============================] - 0s 676us/step - loss: 0.4225 - accuracy: 0.8667 - val_loss: 0.4547 - val_accuracy: 0.9000\n",
            "Epoch 11/20\n",
            "120/120 [==============================] - 0s 734us/step - loss: 0.3986 - accuracy: 0.8833 - val_loss: 0.4377 - val_accuracy: 0.8667\n",
            "Epoch 12/20\n",
            "120/120 [==============================] - 0s 663us/step - loss: 0.3773 - accuracy: 0.9417 - val_loss: 0.4228 - val_accuracy: 0.9000\n",
            "Epoch 13/20\n",
            "120/120 [==============================] - 0s 674us/step - loss: 0.3698 - accuracy: 0.9250 - val_loss: 0.4013 - val_accuracy: 0.9000\n",
            "Epoch 14/20\n",
            "120/120 [==============================] - 0s 663us/step - loss: 0.3442 - accuracy: 0.9333 - val_loss: 0.4092 - val_accuracy: 0.9000\n",
            "Epoch 15/20\n",
            "120/120 [==============================] - 0s 674us/step - loss: 0.3395 - accuracy: 0.9250 - val_loss: 0.3758 - val_accuracy: 0.9333\n",
            "Epoch 16/20\n",
            "120/120 [==============================] - 0s 709us/step - loss: 0.3328 - accuracy: 0.9250 - val_loss: 0.3615 - val_accuracy: 0.9667\n",
            "Epoch 17/20\n",
            "120/120 [==============================] - 0s 692us/step - loss: 0.3137 - accuracy: 0.9167 - val_loss: 0.3601 - val_accuracy: 0.9000\n",
            "Epoch 18/20\n",
            "120/120 [==============================] - 0s 708us/step - loss: 0.3113 - accuracy: 0.9667 - val_loss: 0.3464 - val_accuracy: 0.9333\n",
            "Epoch 19/20\n",
            "120/120 [==============================] - 0s 633us/step - loss: 0.3024 - accuracy: 0.9583 - val_loss: 0.3292 - val_accuracy: 0.9333\n",
            "Epoch 20/20\n",
            "120/120 [==============================] - 0s 660us/step - loss: 0.2996 - accuracy: 0.9417 - val_loss: 0.3274 - val_accuracy: 0.9000\n",
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yGwo4m68m7Ix",
        "outputId": "79a74d1b-54a6-4fd5-fad2-73f9b91bc476"
      },
      "source": [
        "#活性化関数をsigmoidに\n",
        "#不安定になる\n",
        "try_1(act=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_23 (Dense)             (None, 12)                60        \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 3)                 39        \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 99\n",
            "Trainable params: 99\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "sgd\n",
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/20\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 1.0964 - accuracy: 0.5000 - val_loss: 1.1286 - val_accuracy: 0.3000\n",
            "Epoch 2/20\n",
            "120/120 [==============================] - 0s 756us/step - loss: 1.0839 - accuracy: 0.4333 - val_loss: 1.1124 - val_accuracy: 0.2667\n",
            "Epoch 3/20\n",
            "120/120 [==============================] - 0s 659us/step - loss: 1.0709 - accuracy: 0.4500 - val_loss: 1.0988 - val_accuracy: 0.2333\n",
            "Epoch 4/20\n",
            "120/120 [==============================] - 0s 757us/step - loss: 1.0613 - accuracy: 0.3750 - val_loss: 1.0854 - val_accuracy: 0.2333\n",
            "Epoch 5/20\n",
            "120/120 [==============================] - 0s 674us/step - loss: 1.0478 - accuracy: 0.3667 - val_loss: 1.0676 - val_accuracy: 0.2333\n",
            "Epoch 6/20\n",
            "120/120 [==============================] - 0s 727us/step - loss: 1.0358 - accuracy: 0.3667 - val_loss: 1.0520 - val_accuracy: 0.2333\n",
            "Epoch 7/20\n",
            "120/120 [==============================] - 0s 636us/step - loss: 1.0260 - accuracy: 0.3750 - val_loss: 1.0379 - val_accuracy: 0.2333\n",
            "Epoch 8/20\n",
            "120/120 [==============================] - 0s 692us/step - loss: 1.0146 - accuracy: 0.3667 - val_loss: 1.0231 - val_accuracy: 0.2333\n",
            "Epoch 9/20\n",
            "120/120 [==============================] - 0s 638us/step - loss: 1.0062 - accuracy: 0.3917 - val_loss: 1.0099 - val_accuracy: 0.2333\n",
            "Epoch 10/20\n",
            "120/120 [==============================] - 0s 686us/step - loss: 0.9939 - accuracy: 0.4083 - val_loss: 0.9928 - val_accuracy: 0.4333\n",
            "Epoch 11/20\n",
            "120/120 [==============================] - 0s 629us/step - loss: 0.9824 - accuracy: 0.4583 - val_loss: 0.9779 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "120/120 [==============================] - 0s 641us/step - loss: 0.9710 - accuracy: 0.6500 - val_loss: 0.9634 - val_accuracy: 0.7000\n",
            "Epoch 13/20\n",
            "120/120 [==============================] - 0s 682us/step - loss: 0.9589 - accuracy: 0.6333 - val_loss: 0.9475 - val_accuracy: 0.7000\n",
            "Epoch 14/20\n",
            "120/120 [==============================] - 0s 738us/step - loss: 0.9474 - accuracy: 0.6500 - val_loss: 0.9322 - val_accuracy: 0.7000\n",
            "Epoch 15/20\n",
            "120/120 [==============================] - 0s 770us/step - loss: 0.9352 - accuracy: 0.7000 - val_loss: 0.9160 - val_accuracy: 0.7000\n",
            "Epoch 16/20\n",
            "120/120 [==============================] - 0s 826us/step - loss: 0.9235 - accuracy: 0.6583 - val_loss: 0.9000 - val_accuracy: 0.7000\n",
            "Epoch 17/20\n",
            "120/120 [==============================] - 0s 655us/step - loss: 0.9094 - accuracy: 0.7083 - val_loss: 0.8852 - val_accuracy: 0.7000\n",
            "Epoch 18/20\n",
            "120/120 [==============================] - 0s 661us/step - loss: 0.8972 - accuracy: 0.6750 - val_loss: 0.8679 - val_accuracy: 0.7333\n",
            "Epoch 19/20\n",
            "120/120 [==============================] - 0s 691us/step - loss: 0.8848 - accuracy: 0.7000 - val_loss: 0.8533 - val_accuracy: 0.7333\n",
            "Epoch 20/20\n",
            "120/120 [==============================] - 0s 662us/step - loss: 0.8729 - accuracy: 0.6750 - val_loss: 0.8376 - val_accuracy: 0.7333\n",
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o39OWx_bnFRT",
        "outputId": "f2c7251c-8990-47d0-a5c6-92333f19e16b"
      },
      "source": [
        "#optimizerをkerasのメソッドに変更\n",
        "try_1(opt=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReLU\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_25 (Dense)             (None, 12)                60        \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3)                 39        \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 99\n",
            "Trainable params: 99\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "keras.SGD\n",
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/20\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 1.1364 - accuracy: 0.4333 - val_loss: 0.9648 - val_accuracy: 0.3667\n",
            "Epoch 2/20\n",
            "120/120 [==============================] - 0s 725us/step - loss: 0.8106 - accuracy: 0.6250 - val_loss: 0.7300 - val_accuracy: 0.7000\n",
            "Epoch 3/20\n",
            "120/120 [==============================] - 0s 716us/step - loss: 0.6738 - accuracy: 0.7083 - val_loss: 0.5740 - val_accuracy: 0.8333\n",
            "Epoch 4/20\n",
            "120/120 [==============================] - 0s 750us/step - loss: 0.6277 - accuracy: 0.6917 - val_loss: 0.4977 - val_accuracy: 0.8333\n",
            "Epoch 5/20\n",
            "120/120 [==============================] - 0s 687us/step - loss: 0.5797 - accuracy: 0.7583 - val_loss: 0.4911 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "120/120 [==============================] - 0s 686us/step - loss: 0.5547 - accuracy: 0.7667 - val_loss: 0.4110 - val_accuracy: 0.8333\n",
            "Epoch 7/20\n",
            "120/120 [==============================] - 0s 682us/step - loss: 0.5030 - accuracy: 0.8000 - val_loss: 0.3887 - val_accuracy: 0.8333\n",
            "Epoch 8/20\n",
            "120/120 [==============================] - 0s 687us/step - loss: 0.5623 - accuracy: 0.7250 - val_loss: 0.4043 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "120/120 [==============================] - 0s 688us/step - loss: 0.4676 - accuracy: 0.8333 - val_loss: 0.3946 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "120/120 [==============================] - 0s 695us/step - loss: 0.4535 - accuracy: 0.8750 - val_loss: 0.3323 - val_accuracy: 0.8333\n",
            "Epoch 11/20\n",
            "120/120 [==============================] - 0s 688us/step - loss: 0.4575 - accuracy: 0.7833 - val_loss: 0.3211 - val_accuracy: 0.9333\n",
            "Epoch 12/20\n",
            "120/120 [==============================] - 0s 660us/step - loss: 0.4489 - accuracy: 0.8667 - val_loss: 0.4507 - val_accuracy: 0.7000\n",
            "Epoch 13/20\n",
            "120/120 [==============================] - 0s 726us/step - loss: 0.4696 - accuracy: 0.7833 - val_loss: 0.3570 - val_accuracy: 0.8333\n",
            "Epoch 14/20\n",
            "120/120 [==============================] - 0s 674us/step - loss: 0.3909 - accuracy: 0.8667 - val_loss: 0.2989 - val_accuracy: 0.8333\n",
            "Epoch 15/20\n",
            "120/120 [==============================] - 0s 740us/step - loss: 0.4230 - accuracy: 0.8167 - val_loss: 0.3109 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "120/120 [==============================] - 0s 664us/step - loss: 0.3742 - accuracy: 0.8500 - val_loss: 0.2620 - val_accuracy: 0.8667\n",
            "Epoch 17/20\n",
            "120/120 [==============================] - 0s 728us/step - loss: 0.3849 - accuracy: 0.8333 - val_loss: 0.2762 - val_accuracy: 0.8333\n",
            "Epoch 18/20\n",
            "120/120 [==============================] - 0s 691us/step - loss: 0.4561 - accuracy: 0.8000 - val_loss: 0.2622 - val_accuracy: 0.8333\n",
            "Epoch 19/20\n",
            "120/120 [==============================] - 0s 703us/step - loss: 0.4931 - accuracy: 0.8167 - val_loss: 0.3546 - val_accuracy: 0.8000\n",
            "Epoch 20/20\n",
            "120/120 [==============================] - 0s 732us/step - loss: 0.3773 - accuracy: 0.8667 - val_loss: 1.5267 - val_accuracy: 0.4667\n",
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vxVhf7FcnicU",
        "outputId": "62cbcc6f-54b9-4da6-99fb-d19d22ff5c16"
      },
      "source": [
        "#optimizerをkerasのメソッドに変更(学習率を少し下げる)\n",
        "#若干安定にはなる\n",
        "try_1(opt=1,learning_rate=0.05)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReLU\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_31 (Dense)             (None, 12)                60        \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 3)                 39        \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 99\n",
            "Trainable params: 99\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "keras.SGD\n",
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/20\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 1.1391 - accuracy: 0.5083 - val_loss: 0.6203 - val_accuracy: 0.7667\n",
            "Epoch 2/20\n",
            "120/120 [==============================] - 0s 663us/step - loss: 0.5371 - accuracy: 0.7417 - val_loss: 0.5548 - val_accuracy: 0.6667\n",
            "Epoch 3/20\n",
            "120/120 [==============================] - 0s 693us/step - loss: 0.4695 - accuracy: 0.7333 - val_loss: 0.4407 - val_accuracy: 0.9333\n",
            "Epoch 4/20\n",
            "120/120 [==============================] - 0s 708us/step - loss: 0.3864 - accuracy: 0.8750 - val_loss: 0.4274 - val_accuracy: 0.8333\n",
            "Epoch 5/20\n",
            "120/120 [==============================] - 0s 710us/step - loss: 0.3557 - accuracy: 0.8500 - val_loss: 0.5416 - val_accuracy: 0.6667\n",
            "Epoch 6/20\n",
            "120/120 [==============================] - 0s 748us/step - loss: 0.3498 - accuracy: 0.8667 - val_loss: 0.3525 - val_accuracy: 0.9333\n",
            "Epoch 7/20\n",
            "120/120 [==============================] - 0s 645us/step - loss: 0.2832 - accuracy: 0.8917 - val_loss: 0.3191 - val_accuracy: 0.8333\n",
            "Epoch 8/20\n",
            "120/120 [==============================] - 0s 716us/step - loss: 0.3120 - accuracy: 0.8667 - val_loss: 0.2993 - val_accuracy: 0.9333\n",
            "Epoch 9/20\n",
            "120/120 [==============================] - 0s 647us/step - loss: 0.3488 - accuracy: 0.8333 - val_loss: 0.3026 - val_accuracy: 0.8333\n",
            "Epoch 10/20\n",
            "120/120 [==============================] - 0s 763us/step - loss: 0.2425 - accuracy: 0.9000 - val_loss: 0.3125 - val_accuracy: 0.8000\n",
            "Epoch 11/20\n",
            "120/120 [==============================] - 0s 753us/step - loss: 0.1806 - accuracy: 0.9333 - val_loss: 0.7544 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "120/120 [==============================] - 0s 741us/step - loss: 0.3215 - accuracy: 0.8667 - val_loss: 0.2341 - val_accuracy: 0.9667\n",
            "Epoch 13/20\n",
            "120/120 [==============================] - 0s 677us/step - loss: 0.3247 - accuracy: 0.8500 - val_loss: 0.2313 - val_accuracy: 0.9667\n",
            "Epoch 14/20\n",
            "120/120 [==============================] - 0s 673us/step - loss: 0.1542 - accuracy: 0.9583 - val_loss: 0.2215 - val_accuracy: 0.9333\n",
            "Epoch 15/20\n",
            "120/120 [==============================] - 0s 683us/step - loss: 0.2273 - accuracy: 0.8583 - val_loss: 0.2045 - val_accuracy: 0.9667\n",
            "Epoch 16/20\n",
            "120/120 [==============================] - 0s 674us/step - loss: 0.1664 - accuracy: 0.9333 - val_loss: 0.4374 - val_accuracy: 0.8000\n",
            "Epoch 17/20\n",
            "120/120 [==============================] - 0s 659us/step - loss: 0.1932 - accuracy: 0.9167 - val_loss: 0.2494 - val_accuracy: 0.9333\n",
            "Epoch 18/20\n",
            "120/120 [==============================] - 0s 732us/step - loss: 0.1746 - accuracy: 0.9333 - val_loss: 0.2102 - val_accuracy: 0.8333\n",
            "Epoch 19/20\n",
            "120/120 [==============================] - 0s 681us/step - loss: 0.1664 - accuracy: 0.9167 - val_loss: 0.8712 - val_accuracy: 0.7000\n",
            "Epoch 20/20\n",
            "120/120 [==============================] - 0s 675us/step - loss: 0.2076 - accuracy: 0.9167 - val_loss: 0.4227 - val_accuracy: 0.8000\n",
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WO8UoGF2xeU"
      },
      "source": [
        "## 分類 (mnist)\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "### [try]\n",
        "-  load_mnistのone_hot_labelをFalseに変更しよう (error)\n",
        "-  誤差関数をsparse_categorical_crossentropyに変更しよう\n",
        "-  Adamの引数の値を変更しよう\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2wYkCR82xeV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "5e56baac-7e93-409e-d43b-8e3d2e34170e"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from data.mnist import load_mnist\n",
        "\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "#print(x_train, d_train)\n",
        "#print(x_test, d_test)\n",
        "\n",
        "# 必要なライブラリのインポート、最適化手法はAdamを使う\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# モデル作成\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# バッチサイズ、エポック数\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#残念ながらError解決せず\n",
        "#何だかvalueがNoneと言われる(value自体はnumpyか何かのデータ配列を望んでいる様子)\n",
        "#追いかけても良いけど・・・・tensorflowの世代ミスマッチで廃止されたI/F使っているのか？\n",
        "#仕方ないのでafterのコードも見てみるが特に注釈もなく\n",
        "#まぁこれはこのままレポートにしてこのまま提出する事にしましょう(差戻しならば追いかける)\n",
        "history = model.fit(x=x_train, y=d_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, d_test))\n",
        "loss = model.evaluate(x_test, d_test, verbose=0)\n",
        "print('Test loss:', loss[0])\n",
        "print('Test accuracy:', loss[1])\n",
        "#Accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dddcd7bf1f94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#仕方ないのでafterのコードも見てみるが特に注釈もなく\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#まぁこれはこのままレポートにしてこのまま提出する事にしましょう(差戻しならば追いかける)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    315\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvhat_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0mp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm_t\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m           y = ops.convert_to_tensor_v2(\n\u001b[0;32m--> 903\u001b[0;31m               y, dtype_hint=x.dtype.base_dtype, name=\"y\")\n\u001b[0m\u001b[1;32m    904\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m           \u001b[0;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    284\u001b[0m                                          as_ref=False):\n\u001b[1;32m    285\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    263\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    264\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    266\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m   const_tensor = g.create_op(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    435\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: None values not supported."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxKej7Sp2xeX"
      },
      "source": [
        "## CNN分類 (mnist)\n",
        "#### 実行に時間がかかるため割愛"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hURFjr2xeY"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from data.mnist import load_mnist\n",
        "\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "\n",
        "# 行列として入力するための加工\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "\n",
        "# 必要なライブラリのインポート、最適化手法はAdamを使う\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# バッチサイズ、エポック数\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "history = model.fit(x_train, d_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, d_test))\n",
        "\n",
        "#Accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXySpACy2xea"
      },
      "source": [
        "## cifar10\n",
        "#### 実行に時間がかかるため割愛\n",
        "データセット cifar10<br>\n",
        "32x32ピクセルのカラー画像データ<br>\n",
        "10種のラベル「飛行機、自動車、鳥、猫、鹿、犬、蛙、馬、船、トラック」<br>\n",
        "トレーニングデータ数:50000, テストデータ数:10000<br>\n",
        "http://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QpyfW9i2xeb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "#CIFAR-10のデータセットのインポート\n",
        "from keras.datasets import cifar10\n",
        "(x_train, d_train), (x_test, d_test) = cifar10.load_data()\n",
        "\n",
        "#CIFAR-10の正規化\n",
        "from keras.utils import to_categorical\n",
        "  \n",
        "# 特徴量の正規化\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255.\n",
        " \n",
        "# クラスラベルの1-hotベクトル化\n",
        "d_train = to_categorical(d_train, 10)\n",
        "d_test = to_categorical(d_test, 10)\n",
        " \n",
        "# CNNの構築\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "import numpy as np\n",
        " \n",
        "model = Sequential()\n",
        " \n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        " \n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "# コンパイル\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        " \n",
        "#訓練\n",
        "history = model.fit(x_train, d_train, epochs=20)\n",
        " \n",
        "# モデルの保存\n",
        "model.save('./CIFAR-10.h5')\n",
        " \n",
        "#評価 & 評価結果出力\n",
        "print(model.evaluate(x_test, d_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsTzy5dQ2xee"
      },
      "source": [
        "## RNN\n",
        "\n",
        "2進数足し算の予測\n",
        "\n",
        "Keras RNNのドキュメント\n",
        "https://keras.io/ja/layers/recurrent/#simplernn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBLhVkny2xef"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "### [try]\n",
        "-  RNNの出力ノード数を128に変更\n",
        "-  RNNの出力活性化関数を sigmoid に変更\n",
        "-  RNNの出力活性化関数を tanh に変更\n",
        "-  最適化方法をadamに変更\n",
        "-  RNNの入力 Dropout を0.5に設定\n",
        "-  RNNの再帰 Dropout を0.3に設定\n",
        "-  RNNのunrollをTrueに設定\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouD9196W2xeh"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def try_2(units=16,act=\"relu\",act_l=\"sigmoid\",opt=\"sgd\",\n",
        "                  dropout=0,\n",
        "                  recurrent_dropout=0,\n",
        "                  unroll = False\n",
        "          ):\n",
        "    # logging levelを変更\n",
        "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    import keras\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers.core import Dense, Dropout,Activation\n",
        "    from keras.layers.wrappers import TimeDistributed\n",
        "    from keras.optimizers import SGD\n",
        "    from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "    # データを用意\n",
        "    # 2進数の桁数\n",
        "    binary_dim = 8\n",
        "    # 最大値 + 1\n",
        "    largest_number = pow(2, binary_dim)\n",
        "\n",
        "    # largest_numberまで2進数を用意\n",
        "    binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T,axis=1)[:, ::-1]\n",
        "\n",
        "\n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2, size=20000)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2, size=20000)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "\n",
        "    x_int = []\n",
        "    x_bin = []\n",
        "    for i in range(10000):\n",
        "        x_int.append(np.array([a_int[i], b_int[i]]).T)\n",
        "        x_bin.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "    x_int_test = []\n",
        "    x_bin_test = []\n",
        "    for i in range(10001, 20000):\n",
        "        x_int_test.append(np.array([a_int[i], b_int[i]]).T)\n",
        "        x_bin_test.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "    x_int = np.array(x_int)\n",
        "    x_bin = np.array(x_bin)\n",
        "    x_int_test = np.array(x_int_test)\n",
        "    x_bin_test = np.array(x_bin_test)\n",
        "\n",
        "\n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int][0:10000]\n",
        "    d_bin_test = binary[d_int][10001:20000]\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(SimpleRNN(units=units, #16,\n",
        "                  return_sequences=True,\n",
        "                  input_shape=[8, 2],\n",
        "                  go_backwards=False,\n",
        "                  activation=act,\n",
        "                  dropout=dropout,\n",
        "                  recurrent_dropout=recurrent_dropout,\n",
        "                  unroll = unroll,\n",
        "                ))\n",
        "    # 出力層\n",
        "    model.add(Dense(1, activation=act_l, input_shape=(-1,2)))\n",
        "    model.summary()\n",
        "    if opt==\"sgd\":\n",
        "        model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
        "    else:\n",
        "        model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(x_bin, d_bin.reshape(-1, 8, 1), epochs=5, batch_size=2)\n",
        "\n",
        "    # テスト結果出力\n",
        "    score = model.evaluate(x_bin_test, d_bin_test.reshape(-1,8,1), verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE3m7GrhpCZL",
        "outputId": "29546e5a-d96f-4672-d085-b61467747b78"
      },
      "source": [
        "#デフォルト\n",
        "try_2()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_4 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 49s 5ms/step - loss: 0.0954 - accuracy: 0.8981\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 49s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 49s 5ms/step - loss: 8.0596e-04 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 49s 5ms/step - loss: 4.8557e-04 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 49s 5ms/step - loss: 3.4277e-04 - accuracy: 1.0000\n",
            "Test loss: 0.000296252079930731\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF3_w322vxej",
        "outputId": "303b209c-0ba7-4b17-940c-d0b846989769"
      },
      "source": [
        "#出力層を128に増やす(少し性能が上がる)\n",
        "try_2(units=128)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_7 (SimpleRNN)     (None, 8, 128)            16768     \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 8, 1)              129       \n",
            "=================================================================\n",
            "Total params: 16,897\n",
            "Trainable params: 16,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 51s 5ms/step - loss: 0.0647 - accuracy: 0.9340\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 51s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 51s 5ms/step - loss: 6.5358e-04 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 51s 5ms/step - loss: 3.8603e-04 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 51s 5ms/step - loss: 2.6887e-04 - accuracy: 1.0000\n",
            "Test loss: 0.0002321572416231572\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GIkR8b8tnJx",
        "outputId": "a57a1334-d15e-4bac-85cc-1588c022d483"
      },
      "source": [
        "#活性化関数をsigmoidに変更(性能が落ちる)\n",
        "try_2(act=\"sigmoid\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_5 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 50s 5ms/step - loss: 0.2500 - accuracy: 0.5155\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 49s 5ms/step - loss: 0.2484 - accuracy: 0.5337\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 50s 5ms/step - loss: 0.2459 - accuracy: 0.5661\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 50s 5ms/step - loss: 0.2364 - accuracy: 0.6513\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 49s 5ms/step - loss: 0.1675 - accuracy: 0.8142\n",
            "Test loss: 0.08980920342895218\n",
            "Test accuracy: 0.9602585434913635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKnmD1U8uUOu",
        "outputId": "a78bcddf-c6eb-4b1c-a58d-8a23bad673ac"
      },
      "source": [
        "#出力活性化関数をtanhに変更(すこしだけ性能が落ちる)\n",
        "try_2(act_l=\"tanh\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_6 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 50s 5ms/step - loss: 0.0516 - accuracy: 0.9441\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 49s 5ms/step - loss: 0.0101 - accuracy: 0.9926\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 49s 5ms/step - loss: 0.0055 - accuracy: 0.9966\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 49s 5ms/step - loss: 0.0028 - accuracy: 0.9988\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 50s 5ms/step - loss: 0.0016 - accuracy: 0.9996\n",
            "Test loss: 0.0006023046667244241\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "httCUwgFwSp0",
        "outputId": "27521f29-f5ed-4a67-b108-4d3c2181c4e8"
      },
      "source": [
        "#optimizerをadamに変更(微細だけどLossが減る)\n",
        "try_2(opt=\"adam\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_8 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 53s 5ms/step - loss: 0.0934 - accuracy: 0.8891\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 53s 5ms/step - loss: 0.0065 - accuracy: 0.9999\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 53s 5ms/step - loss: 2.3071e-04 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 1.5997e-05 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 53s 5ms/step - loss: 1.1791e-06 - accuracy: 1.0000\n",
            "Test loss: 2.4886070756688616e-07\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E_mePGgxyza",
        "outputId": "0aa737a0-ecba-4f27-a258-2c1c34d25a3d"
      },
      "source": [
        "#ドロップアウト率変更等を一気に(各エポックの実行速度ははやくなる、ただし精度はかなり落ちる)\n",
        "try_2(dropout=0.5,recurrent_dropout=0.3, unroll = True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_9 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 27s 3ms/step - loss: 0.2428 - accuracy: 0.5610\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 26s 3ms/step - loss: 0.2338 - accuracy: 0.5892\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 26s 3ms/step - loss: 0.2263 - accuracy: 0.6083\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 26s 3ms/step - loss: 0.2200 - accuracy: 0.6126\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 26s 3ms/step - loss: 0.2160 - accuracy: 0.6167\n",
            "Test loss: 0.21645867168539726\n",
            "Test accuracy: 0.7746149897575378\n"
          ]
        }
      ]
    }
  ]
}